{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "176ad0b3",
   "metadata": {},
   "source": [
    "# 1)Чтение данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2959f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a7e56f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "data = pd.read_csv('C:/Users/shemy/Downloads/master2.csv')\n",
    "\n",
    "# Предобработка данных\n",
    "# Удалим ненужные столбцы и пропуски\n",
    "data = data.drop(columns=['country', 'year', 'sex', 'age', 'population', 'gdp_for_year', 'gdp_per_capita'], errors='ignore')\n",
    "\n",
    "# Заполним пропуски\n",
    "data.fillna(0, inplace=True)\n",
    "\n",
    "# Вытаскиваем числовые признаки\n",
    "numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "X = data[numeric_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2647e84c",
   "metadata": {},
   "source": [
    "# 2)KMeans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14b1c035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество обнаруженных кластеров: 3\n",
      "Silhouette Score для KMeans: 0.8832307929120485\n"
     ]
    }
   ],
   "source": [
    "# Определяем количество кластеров\n",
    "n_clusters = 3  # Вы можете изменить это значение, если хотите\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "kmeans_labels = kmeans.fit_predict(X)\n",
    "\n",
    "# Подсчет количества найденных кластеров\n",
    "unique_clusters = np.unique(kmeans_labels)\n",
    "num_clusters = len(unique_clusters) - (1 if -1 in unique_clusters else 0)  # Исключаем шум, если он есть\n",
    "\n",
    "# Оценка качества кластеризации\n",
    "silhouette_kmeans = silhouette_score(X, kmeans_labels)\n",
    "\n",
    "# Вывод результатов\n",
    "print(f'Количество обнаруженных кластеров: {num_clusters}')\n",
    "print(f'Silhouette Score для KMeans: {silhouette_kmeans}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bebf7b",
   "metadata": {},
   "source": [
    "# 3)DBSCAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a7ea1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество обнаруженных кластеров: 2\n",
      "Silhouette Score для DBSCAN: 0.49556618120318274\n"
     ]
    }
   ],
   "source": [
    "# Создадим некоторые данные для кластеризации\n",
    "X, y = make_blobs(n_samples=100, centers=3, cluster_std=0.60, random_state=0)\n",
    "\n",
    "# Превращаем в DataFrame для удобства\n",
    "df = pd.DataFrame(X, columns=['feature1', 'feature2'])\n",
    "\n",
    "# Масштабируем данные\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(df)\n",
    "\n",
    "# Применяем DBSCAN\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "dbscan.fit(scaled_features)\n",
    "\n",
    "# Получаем метки кластеров\n",
    "labels = dbscan.labels_\n",
    "\n",
    "# Подсчет количества обнаруженных кластеров, исключая шум (-1)\n",
    "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "# Проверим, были ли найдены кластеры\n",
    "if n_clusters > 0:  # Убедимся, что найдены кластеры\n",
    "    silhouette_avg = silhouette_score(scaled_features, labels)\n",
    "    print(f\"Количество обнаруженных кластеров: {n_clusters}\")\n",
    "    print(f\"Silhouette Score для DBSCAN: {silhouette_avg}\")\n",
    "else:\n",
    "    print(\"Недостаточно кластеров, чтобы рассчитать Silhouette Score.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b31964",
   "metadata": {},
   "source": [
    "# 4)AgglomerativeClustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06bf1ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество обнаруженных кластеров: 3\n",
      "Silhouette Score для агломеративной кластеризации: 0.9097997548299109\n"
     ]
    }
   ],
   "source": [
    "# Применение агломеративной кластеризации\n",
    "n_clusters = 3  # Задаем желаемое количество кластеров\n",
    "agglo = AgglomerativeClustering(n_clusters=n_clusters)\n",
    "agglo_labels = agglo.fit_predict(X)\n",
    "\n",
    "# Определение уникальных меток кластеров и подсчет количества обнаруженных кластеров\n",
    "unique_clusters = np.unique(agglo_labels)\n",
    "num_clusters = len(unique_clusters)  # Общее количество обнаруженных кластеров\n",
    "\n",
    "# Оценка качества кластеризации\n",
    "silhouette_agglo = silhouette_score(X, agglo_labels)\n",
    "\n",
    "# Вывод результатов\n",
    "print(f'Количество обнаруженных кластеров: {num_clusters}')\n",
    "print(f'Silhouette Score для агломеративной кластеризации: {silhouette_agglo}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6153d00b",
   "metadata": {},
   "source": [
    "# 5)Сравнение методов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c0c4a168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Метод  Корректность в %\n",
      "0                   KMeans             88.32\n",
      "1                   DBSCAN             49.55\n",
      "2  AgglomerativeClustering             90.97\n"
     ]
    }
   ],
   "source": [
    "table1 = [[\"KMeans\", 88.32],\n",
    "         [\"DBSCAN\", 49.55],\n",
    "         [\"AgglomerativeClustering\", 90.97]]\n",
    "df = pd.DataFrame(table1, columns=[\"Метод\", \"Корректность в %\"])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b88725c",
   "metadata": {},
   "source": [
    "# 6)Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e1b02c",
   "metadata": {},
   "source": [
    "Лучший результат получился с использованием метода кластеризации AgglomerativeClustering"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
